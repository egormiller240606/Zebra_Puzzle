# Zebra Puzzle Simulation

## Описание проекта

Этот проект представляет собой агентную модель симуляции "Zebra Puzzle" (загадки Эйнштейна), где агенты (жители домов) путешествуют между домами, обмениваются питомцами и обновляют свои знания о других агентах. Симуляция основана на дискретно-событийном подходе с приоритетами событий.

## Требования

- Python 3.7+
- Стандартные библиотеки: `random`, `heapq`, `typing`

## Установка и запуск

1. Убедитесь, что файлы данных находятся в директории `data/`:
    - `data/zebra-01.csv` - инициализация агентов и домов
    - `data/ZEBRA-strategies.csv` - стратегии агентов
    - `data/ZEBRA-geo.csv` - матрица расстояний

2. Запустите симуляцию:
    ```bash
    python Simulation.py
    ```

3. Вывод:
    - CSV-лог событий сохраняется в `data/simulation_log.csv`
    - Финальные знания агентов
    - График нарастающего итога событий сохраняется в `data/cumulative_events_gpaph.png`

## Анализ результатов симуляции

Для анализа результатов симуляции используйте скрипт `log_analyzer.py`:

```bash
python log_analyzer.py
```

Анализатор предоставляет:
- Сводный отчет по симуляции (количество событий, распределение по типам, статистика поездок и обменов)
- График нарастающего итога событий по типам
- Анализ эволюции знаний агентов

## Структура файлов данных

### data/zebra-01.csv
Инициализация агентов и домов. Формат:
```
house_id;color;nation;drink;smoke;pet
1;Red;Russian;Water;Marlboro;Dog
2;Blue;English;Beer;Pall Mall;Cat
...
```

- `house_id`: уникальный идентификатор дома (1-6)
- `color`: цвет дома
- `nation`: национальность агента
- `drink`: предпочитаемый напиток
- `smoke`: марка сигарет
- `pet`: питомец

### data/ZEBRA-strategies.csv
Стратегии поведения агентов. Формат:
```
agent_id;nation;route_prob1;route_prob2;route_prob3;route_prob4;route_prob5;route_prob6;house_exch_prob;pet_exch_prob
1;Russian;10;5;0;0;0;0;20;30
...
```

- `route_prob1-6`: вероятности выбора маршрута к домам соответствующих цветов (индексы 1-6)
- `house_exch_prob`: вероятность обмена домами (%)
- `pet_exch_prob`: вероятность обмена питомцами (%)

### data/ZEBRA-geo.csv
Матрица расстояний между домами. Формат:
```
house_id;color;dist_to_1;dist_to_2;dist_to_3;dist_to_4;dist_to_5;dist_to_6
1;Red;0;4;NA;NA;NA;1
...
```

- `NA`: недоступный маршрут
- Числа: время путешествия в единицах времени

## Архитектура кода

### Основные классы

#### Класс Agent
Представляет агента-жителя.

**Атрибуты:**
- `id`: уникальный идентификатор
- `nationality`: национальность
- `drink`, `cigarettes`, `pet`: характеристики
- `house_id`: дом-владелец
- `location`: текущая локация
- `is_travelling`: флаг путешествия
- `route_probs`: словарь вероятностей маршрутов
- `house_exchange_prob`, `pet_exchange_prob`: вероятности обменов
- `knowledge`: словарь известной информации о других агентах

**Методы:**
- `update_knowledge(other_agent)`: обновляет знания об агенте
- `choose_trip_target()`: выбирает цель путешествия на основе вероятностей и географии

#### Класс House
Представляет дом/локацию.

**Атрибуты:**
- `id`: идентификатор дома
- `color`: цвет дома
- `owner_id`: владелец
- `present_agents`: множество присутствующих агентов

**Методы:**
- `enter(agent_id)`, `leave(agent_id)`: управление присутствием
- `set_owner(new_owner_id)`: смена владельца
- `is_owner_home()`: проверка, дома ли владелец

#### Класс Event (базовый)
Базовый класс для событий симуляции.

**Подклассы:**
- `StartTripEvent`: начало путешествия
- `FinishTripEvent`: завершение путешествия
- `ChangePetEvent`: обмен питомцами
- `ChangeHouseEvent`: обмен домами

#### Класс Environment
Управляет всей симуляцией.

**Атрибуты:**
- `agents`: словарь агентов
- `houses`: словарь домов
- `travel_matrix`: матрица расстояний
- `time`: текущее время
- `event_queue`: очередь событий (heap)
- `log`: список записей лога

**Методы:**
- `push_event(event)`: добавляет событие в очередь
- `run(max_time)`: запускает симуляцию
- `detect_and_generate_exchanges()`: генерирует события обмена питомцами

### Вспомогательные функции

- `parse_csv_line()`: парсит строку CSV
- `log_formatter()`: форматирует запись лога
- `load_strategies()`, `load_initial_data()`, `load_geography()`: загрузка данных
- `build_color_to_prob_index()`: маппинг цветов к индексам вероятностей

## Логика симуляции

### Инициализация
1. Загрузка данных из CSV-файлов
2. Создание агентов и домов
3. Инициализация знаний (каждый знает себя)
4. Планировка первых путешествий для всех агентов

### Цикл симуляции
Пока есть события и время ≤ max_time:
1. Извлечение батча событий на текущем времени
2. Обработка событий по приоритетам:
   - `FinishTrip` (приоритет 1)
   - `Exchange` (приоритет 2)
   - `StartTrip` (приоритет 3)
3. Логирование событий
4. Генерация новых событий (обмены, новые путешествия)

### Обработка событий

#### StartTripEvent
- Проверка возможности путешествия
- Установка флага путешествия
- Расчет времени прибытия
- Создание FinishTripEvent

#### FinishTripEvent
- Обновление локации агента
- Проверка успеха (встреча с владельцем дома)
- При успехе: обмен знаниями между присутствующими
- Генерация событий обмена питомцами (если условия выполнены)

#### ChangePetEvent
- Циклический обмен питомцами между участниками
- Обновление знаний всех присутствующих в доме

#### ChangeHouseEvent
- Циклический обмен домами между участниками
- Обновление знаний всех присутствующих в доме
- Обновление владельцев домов

### Планировка путешествий
После FinishTrip:
- Если агент дома: планирует новое путешествие (выбор цели по вероятностям)
- Если не дома: планирует возвращение домой

### Обмен питомцами
- Происходит после успешных прибытий
- Для каждого дома с ≥2 агентами
- Агенты участвуют с вероятностью `pet_exchange_prob`
- Минимум 2 участника (любое количество ≥ 2)
- Циклический обмен: A→B→C→...→A

### Обмен домами
- Происходит после успешных прибытий в дом прибытия
- Для дома прибытия с ≥2 агентами и владельцем дома
- Агенты участвуют с вероятностью `house_exchange_prob`
- Минимум 2 участника
- Циклический обмен домами: A→B→C→A
- После обмена агенты планируют поездки в новые дома, если location != house_id

## Система знаний

Каждый агент ведет словарь `knowledge`:
```python
{
    agent_id: {
        "pet": str,
        "house": int,
        "location": int,
        "t": int  # timestamp последнего обновления
    }
}
```

- Изначально знает только себя
- Обновляется при встречах с владельцами домов
- Обновляется при обменах питомцами (все присутствующие узнают новые питомцы участников)
- Обновляется при обменах домами (все присутствующие узнают новые дома участников)
- Каждый элемент знаний содержит timestamp последнего обновления


### StartTrip
`event_number;time;StartTrip;nationality;from_house;to_house`

### FinishTrip
- Домой: `event_number;time;FinishTrip;nationality;house`
- Не домой: `event_number;time;FinishTrip;success;nationality;house`
  - `success`: 1 (встретил владельца), 0 (не встретил)

### ChangePet
`event_number;time;ChangePet;qty_participants;nat1;nat2;[nat3;...];pet1;pet2;[pet3;...]`

### changeHouse
`event_number;time;changeHouse;qty_participants;nat1;nat2;[nat3;...];house1;house2;[house3;...]`


## Пример и анализ лога

Лог симуляции содержит тысячи событий и показывает сложную динамику обменов между агентами. Вот пример типичного фрагмента с обменами:

```
6370 примеров событий (до времени 2000)

Примеры событий:
1;0;StartTrip;Russian;1;3
2;0;StartTrip;Chinese;3;5
...
41;12;changeHouse;2;German;French;5;4
76;21;ChangePet;2;English;Chinese;Zebra;Cat
272;88;ChangePet;2;Russian;German;Fish;Dog
591;188;changeHouse;2;French;American;2;6
...

---- KNOWLEDGE ----
1;{1: {'pet': 'Dog', 'house': 2, 'location': 2, 't': 1921}, 4: {'pet': 'Humpster', 'house': 5, 'location': 6, 't': 1829}, 2: {'pet': 'Cat', 'house': 4, 'location': 2, 't': 1921}, 5: {'pet': 'Fish', 'house': 6, 'location': 6, 't': 1919}, 6: {'pet': 'Dog', 'house': 1, 'location': 1, 't': 1868}, 3: {'pet': 'Dog', 'house': 3, 'location': 1, 't': 1576}}
2;{2: {'pet': 'Zebra', 'house': 1, 'location': 1, 't': 1976}, 3: {'pet': 'Cat', 'house': 3, 'location': 5, 't': 1305}, 4: {'pet': 'Fish', 'house': 6, 'location': 1, 't': 1987}, 5: {'pet': 'Humpster', 'house': 5, 'location': 5, 't': 1686}, 1: {'pet': 'Dog', 'house': 2, 'location': 2, 't': 1921}, 6: {'pet': 'Cat', 'house': 4, 'location': 1, 't': 1976}}
...
```

Агенты активно обмениваются домами и питомцами, что приводит к сложной сети знаний. Каждый агент знает информацию о других участниках обменов, включая timestamp последнего обновления.

## Детали реализации

### Приоритеты событий
- `EVENT_PRIORITY_FINISH_TRIP = 1`
- `EVENT_PRIORITY_EXCHANGE = 2`
- `EVENT_PRIORITY_START_TRIP = 3`

### Обработка батчей
События на одном времени обрабатываются в порядке приоритетов для корректного моделирования последовательности.

### Генерация обменов питомцами
- Только после `FinishTrip` событий
- Для каждого дома отдельно
- **Случайный выбор участников:**
  - Для каждого агента в доме генерируется случайное число от 1 до 100
  - Если число ≤ `pet_exchange_prob` агента, он добавляется в список готовых к обмену
  - Минимум 2 участника для обмена (любое количество участников ≥ 2)
- Циклический сдвиг питомцев: A→B→C→...→A (где все готовые участники)

### Генерация обменов домами
- Только после успешных `FinishTrip` событий (success=1) в дом прибытия
- Для дома прибытия с ≥2 агентами и владельцем дома
- **Случайный выбор участников:**
  - Для каждого агента в доме генерируется случайное число от 1 до 100
  - Если число ≤ `house_exchange_prob` агента, он добавляется в список готовых к обмену
  - Минимум 2 участника для обмена (любое количество участников ≥ 2)
- Циклический сдвиг домов: A→B→C→...→A (где все готовые участники)
- После обмена планируются поездки участников в новые дома, если location != house_id

### Выбор маршрутов
- Исключение текущей локации
- Взвешенный случайный выбор по `route_probs`
- При нулевых весах: равномерный случайный выбор

